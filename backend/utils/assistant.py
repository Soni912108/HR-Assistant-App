import time
import os
from openai import OpenAI, RateLimitError, APIError

# Load .env
from dotenv import load_dotenv
load_dotenv()

OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY").strip()
OPENAI_MODEL = os.environ.get("OPENAI_MODEL").strip()


def assistant(hints: str, question: str, file_content: str) -> str:
    """
    Calls the OpenAI chat completion API to generate an assistant response.

    Parameters
    ----------
    hints : str
        Contextual hints or instructions for the assistant.
    question : str
        The user's question to be answered.
    file_content : str
        The extracted text content from the uploaded file.

    Returns
    -------
    str
        The assistant's response as generated by the OpenAI API.

    Raises
    ------
    RateLimitError
        If the OpenAI API rate limit is exceeded.
    APIError
        For other OpenAI API errors.
    Exception
        For any other unexpected errors.
    """
    try:
        start_time = time.time()
        client = OpenAI(api_key=OPENAI_API_KEY)
        print("[assistant] Sending request to OpenAI API...")

        response = client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[
                {"role": "system", "content": "You are a HR Specialist."},
                {"role": "user", "content": hints},
                {"role": "user", "content": f"Files: {file_content}\n\nQuestion: {question}?"}
            ],
            temperature=0.5
        )

        end_time = time.time()
        print(f"[assistant] OpenAI API call completed in {end_time - start_time:.2f} seconds")
        print(f"[assistant] Response received: {response.choices[0].message.content[:100]}...")
        return response.choices[0].message.content

    except RateLimitError as e:
        print(f"[assistant] OpenAI Rate limit error: {str(e)}")
        raise
    except APIError as e:
        print(f"[assistant] OpenAI API error: {str(e)}")
        raise
    except Exception as e:
        print(f"[assistant] Unexpected assistant error: {str(e)}")
        raise


# streaming version 
def assistant_stream(hints: str, question: str, file_content: str) -> str:
    """
    Streams tokens from the OpenAI Chat Completions API (>=1.0.0).
    Prints tokens live. Returns the final full message as a string.
    """

    try:
        start_time = time.time()
        client = OpenAI(api_key=OPENAI_API_KEY)
        print("[assistant_stream] Sending request to OpenAI API...")

        stream = client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[
                {"role": "system", "content": "You are a HR Specialist."},
                {"role": "user", "content": hints},
                {"role": "user", "content": f"Files: {file_content}\n\nQuestion: {question}?"}
            ],
            temperature=0.5,
            stream=True,
        )

        final_answer = ""  # we accumulate the full response
        print("[assistant_stream] \n--- Stream Start ---\n")

        for event in stream:
            # Each event is a token or chunk
            if event.choices and event.choices[0].delta.content:
                token = event.choices[0].delta.content
                final_answer += token
                print(token, end="", flush=True)

        print("[assistant_stream] \n\n--- Stream End ---\n")

        end_time = time.time()
        print(f"[assistant_stream]: Total time taken: {end_time - start_time} seconds")
        return final_answer

    except RateLimitError as e:
        print(f"[assistant_stream]: OpenAI Rate limit error: {str(e)}")
        raise
    except APIError as e:
        print(f"[assistant_stream]: OpenAI API error: {str(e)}")
        raise
    except Exception as e:
        print(f"[assistant_stream]: Assistant error: {str(e)}")
        raise